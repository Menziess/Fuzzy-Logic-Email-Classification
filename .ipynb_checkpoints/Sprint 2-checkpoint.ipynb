{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 2\n",
    "\n",
    "In de [eerste sprint](https://trello.com/b/RtxQyUB4/sprint-1-17-nov) werken we aan de volgende taken:\n",
    "\n",
    "1. [Email file reading methode schrijven](https://trello.com/c/L3ISKIgf/4-email-file-reading-methode-schrijven)\n",
    "2. [Cleaning methode schrijven](https://trello.com/c/QCD8JKLK/2-cleaning-methode-schrijven) + [Tokenize methode schrijven](https://trello.com/c/UrXLnJBi/3-tokenize-methode-schrijven)\n",
    "3. [Fuzzy logic model bedenken (inputs, MF's, outputs, rules enz..), Inspirational Paper Lezen](http://ijcsi.org/papers/IJCSI-10-3-2-48-58.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Email file reading methode schrijven\n",
    "\n",
    "Voor dit project staan resource files opgeslagen in de folder: *res*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/stefan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/stefan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Global variable containing body of .txt file\n",
    "body = ''\n",
    "\n",
    "# Opening the example email file for reading\n",
    "# using a context manager (safe)\n",
    "with open('res/email.txt', 'r') as f:\n",
    "    size_to_read = 270\n",
    "    body = f.read(size_to_read)\n",
    "    \n",
    "\n",
    "\n",
    "def tokenize(body):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(body)\n",
    "    # print('TOKENS:\\n', tokens[:100])\n",
    "    # Convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # Remove punctuation from each word\n",
    "    import string\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # Remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # Filter out stop words\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # Stemming of words\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    porter = PorterStemmer()\n",
    "    words = [porter.stem(word) for word in words]\n",
    "\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fuzzy logic model bedenken (inputs, MF's, outputs, rules enz..), Inspirational Paper Lezen\n",
    "\n",
    "Paper: [http://ijcsi.org/papers/IJCSI-10-3-2-48-58.pdf](http://ijcsi.org/papers/IJCSI-10-3-2-48-58.pdf)\n",
    "\n",
    "In hoofdstuk 3.1 Fuzzy Classification Module, wordt uitgelegd hoe spam woorden worden beoordeeld en gevoed aan een FLS. Net als in het ontwerp van ons project, worden woorden gecleaned, getokenized en vervolgens beoordeeld. \n",
    "\n",
    "Voor elke beoordeling van ieder woord kan een vector worden gemaakt met features (bijvoorbeeld: \"overlap_dept1\", \"sentiment\", \"technische_term\", enz...), zodat alle woorden kunnen worden meeggeven als een vector van feature vectors:\n",
    "\n",
    "$words = [\\overrightarrow{F_1}, \\overrightarrow{F_2}, ..., \\overrightarrow{F_n}]$\n",
    "\n",
    "Elke feature kan als input aan het FLS worden meegegeven, zo dat voor ieder woord een \"ranking\" wordt berekend:\n",
    "\n",
    "$A = \\{f, \\mu_A(f)$ | $ f \\in F_1 \\}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
