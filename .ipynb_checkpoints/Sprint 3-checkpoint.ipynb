{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 3\n",
    "\n",
    "In de [derde sprint](https://trello.com/b/EUxZhLuE/sprint-3-milestone-1-27-nov) werken we aan de volgende taken:\n",
    "\n",
    "1. [Helper Functions](http://localhost:8888/notebooks/Sprint%203.ipynb#Helper-Functions)\n",
    "2. [Top Layer van het Systeem](http://localhost:8888/notebooks/Sprint%203.ipynb#1.-Top-Layer-van-het-Systeem) ~Jim\n",
    "3. [Feature score berekenen van woorden, feature vectors maken](http://localhost:8888/notebooks/Sprint%203.ipynb#2.-Feature-score-berekenen-van-woorden,-feature-vectors-maken) ~Stefan\n",
    "4. [Fuzzy Logic Toolbox implementeren]() ~Peter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Helper Functions\n",
    "\n",
    "In [Sprint 2](http://localhost:8888/notebooks/Sprint%202.ipynb) hebben we methodes gemaakt om woorden te tellen en een intersectie tussen woordenlijsten uit te voeren. Deze methodes kunnen worden gebruikt bij de taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/stefan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/stefan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def tokenize(body):\n",
    "    tokens = word_tokenize(body)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    porter = PorterStemmer()\n",
    "    words = [porter.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "def read_txt(filepath):\n",
    "    with open(filepath, 'r') as t:\n",
    "        body = t.read()\n",
    "        return tokenize(body)\n",
    "    \n",
    "def read_csv(filepath):\n",
    "    with open(filepath, 'r') as c:\n",
    "        reader = csv.reader(c, delimiter=',')\n",
    "        for row in reader:\n",
    "            return row\n",
    "\n",
    "def generate_csv_from_array(filename, array):\n",
    "    with open(\"res/\" + filename + \".csv\", 'w', newline='') as c:\n",
    "        writer = csv.writer(c, delimiter=',')\n",
    "        writer.writerow(array)\n",
    "        \n",
    "def intersection(array1, array2):\n",
    "    \"\"\"Returns a generator, use next(generator)\"\"\"\n",
    "    return (i for i in array1 if i in array2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Top Layer van het Systeem\n",
    "    ~Jim Kamans\n",
    "\n",
    "Er moet een systeem geschreven worden (gedurende alle sprints) die de basis vormt voor het classificeren van meerdere emails, waarbij een overzicht van de classificatie en analyse van de correct en fout geclassificeerde emails wordt getoond.\n",
    "\n",
    "#### 2.1 Inlezen meerdere emails uit folder\n",
    "\n",
    "... leg uit wat je doet in deze stap ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature score berekenen van woorden, feature vectors maken\n",
    "\n",
    "    ~Stefan Schenk\n",
    "    \n",
    "Woorden in een corpus moeten extra features krijgen, namelijk de scores van de mate waarbij ieder woord bij een feature past. Daarna moet de algehele score van alle woorden bij elkaar worden berekend. Dit zullen de inputs zijn voor het Fuzzy Logic Systeem.\n",
    "\n",
    "#### 3.1 Generating Word List\n",
    "\n",
    "In de vorige sprint gebruikten wij de Counter class om distincte woorden te tellen en op te slaan in een dictionary. Jammergenoeg is het lastig om dictionaries uit te breiden met meerdere values.\n",
    "\n",
    "Numpy heeft een methode \"unique\" waarmee hetzelfde doel kan worden bereikt. De values en counts worden opgeslagen in een uitbreidbare np.array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['abdel', '1'],\n",
       "       ['abstorsv', '1'],\n",
       "       ['aid', '1'],\n",
       "       ['al', '7'],\n",
       "       ['alarabi', '1'],\n",
       "       ['alfais', '1'],\n",
       "       ['alqaida', '1'],\n",
       "       ['also', '1'],\n",
       "       ['althani', '1'],\n",
       "       ['alzawahiri', '3'],\n",
       "       ['amr', '1'],\n",
       "       ['amslack', '1'],\n",
       "       ['announc', '2'],\n",
       "       ['approv', '2'],\n",
       "       ['aq', '1'],\n",
       "       ['arab', '3'],\n",
       "       ['arabi', '1'],\n",
       "       ['area', '1'],\n",
       "       ['asad', '1'],\n",
       "       ['ask', '1'],\n",
       "       ['assist', '1'],\n",
       "       ['assistanceeut', '1'],\n",
       "       ['attack', '1'],\n",
       "       ['atttp', '1'],\n",
       "       ['auspic', '1'],\n",
       "       ['baba', '1'],\n",
       "       ['basic', '1'],\n",
       "       ['bureau', '1'],\n",
       "       ['cairo', '6'],\n",
       "       ['call', '3'],\n",
       "       ['case', '2'],\n",
       "       ['ceasefir', '2'],\n",
       "       ['center', '1'],\n",
       "       ['cia', '1'],\n",
       "       ['classifi', '1'],\n",
       "       ['clear', '1'],\n",
       "       ['clinton', '1'],\n",
       "       ['comment', '3'],\n",
       "       ['commun', '1'],\n",
       "       ['contribut', '1'],\n",
       "       ['cooper', '2'],\n",
       "       ['council', '2'],\n",
       "       ['countri', '1'],\n",
       "       ['creat', '2'],\n",
       "       ['crisiss', '1'],\n",
       "       ['current', '1'],\n",
       "       ['date', '3'],\n",
       "       ['day', '1'],\n",
       "       ['demand', '1'],\n",
       "       ['depart', '2'],\n",
       "       ['dh', '1'],\n",
       "       ['diplomat', '1'],\n",
       "       ['direct', '1'],\n",
       "       ['dist', '1'],\n",
       "       ['dni', '1'],\n",
       "       ['doc', '2'],\n",
       "       ['draft', '1'],\n",
       "       ['e', '2'],\n",
       "       ['east', '1'],\n",
       "       ['econom', '1'],\n",
       "       ['email', '1'],\n",
       "       ['embassi', '3'],\n",
       "       ['emerg', '1'],\n",
       "       ['end', '1'],\n",
       "       ['est', '1'],\n",
       "       ['execut', '1'],\n",
       "       ['expect', '1'],\n",
       "       ['famili', '1'],\n",
       "       ['februari', '4'],\n",
       "       ['fight', '1'],\n",
       "       ['follow', '1'],\n",
       "       ['forc', '2'],\n",
       "       ['foreign', '4'],\n",
       "       ['four', '1'],\n",
       "       ['friend', '1'],\n",
       "       ['full', '1'],\n",
       "       ['fw', '1'],\n",
       "       ['gcc', '2'],\n",
       "       ['good', '1'],\n",
       "       ['govern', '1'],\n",
       "       ['gulf', '1'],\n",
       "       ['gunfir', '1'],\n",
       "       ['halt', '1'],\n",
       "       ['help', '1'],\n",
       "       ['hillari', '1'],\n",
       "       ['hom', '1'],\n",
       "       ['horn', '1'],\n",
       "       ['host', '1'],\n",
       "       ['immedi', '1'],\n",
       "       ['indic', '1'],\n",
       "       ['individu', '1'],\n",
       "       ['intern', '2'],\n",
       "       ['issu', '1'],\n",
       "       ['item', '1'],\n",
       "       ['jacobj', '1'],\n",
       "       ['jake', '1'],\n",
       "       ['jc', '1'],\n",
       "       ['joint', '1'],\n",
       "       ['kill', '1'],\n",
       "       ['last', '1'],\n",
       "       ['lavrov', '1'],\n",
       "       ['leader', '1'],\n",
       "       ['leagu', '2'],\n",
       "       ['least', '1'],\n",
       "       ['leavereut', '1'],\n",
       "       ['letter', '1'],\n",
       "       ['longstand', '1'],\n",
       "       ['lull', '1'],\n",
       "       ['mail', '2'],\n",
       "       ['mainli', '1'],\n",
       "       ['materi', '1'],\n",
       "       ['meet', '2'],\n",
       "       ['middl', '1'],\n",
       "       ['minist', '5'],\n",
       "       ['mission', '2'],\n",
       "       ['monitor', '1'],\n",
       "       ['monitorspsembassi', '1'],\n",
       "       ['muslim', '3'],\n",
       "       ['nation', '1'],\n",
       "       ['nctc', '1'],\n",
       "       ['neighborhood', '1'],\n",
       "       ['nmcc', '1'],\n",
       "       ['nss', '1'],\n",
       "       ['observ', '1'],\n",
       "       ['open', '1'],\n",
       "       ['oper', '1'],\n",
       "       ['opportun', '1'],\n",
       "       ['opposit', '4'],\n",
       "       ['opsalert', '1'],\n",
       "       ['opsembassi', '1'],\n",
       "       ['osc', '1'],\n",
       "       ['osd', '1'],\n",
       "       ['otherwis', '1'],\n",
       "       ['partial', '1'],\n",
       "       ['peacekeep', '1'],\n",
       "       ['peopl', '3'],\n",
       "       ['peoplesembassi', '1'],\n",
       "       ['permit', '1'],\n",
       "       ['pleas', '1'],\n",
       "       ['pm', '2'],\n",
       "       ['polit', '1'],\n",
       "       ['posit', '1'],\n",
       "       ['presid', '1'],\n",
       "       ['prime', '1'],\n",
       "       ['provid', '3'],\n",
       "       ['qatari', '1'],\n",
       "       ['rebel', '1'],\n",
       "       ['receiv', '1'],\n",
       "       ['recogn', '1'],\n",
       "       ['recognit', '1'],\n",
       "       ['record', '1'],\n",
       "       ['reiter', '1'],\n",
       "       ['reject', '1'],\n",
       "       ['releas', '1'],\n",
       "       ['reli', '1'],\n",
       "       ['report', '3'],\n",
       "       ['request', '1'],\n",
       "       ['resolut', '3'],\n",
       "       ['rest', '1'],\n",
       "       ['resum', '1'],\n",
       "       ['reuter', '1'],\n",
       "       ['rocket', '1'],\n",
       "       ['russia', '1'],\n",
       "       ['russian', '1'],\n",
       "       ['said', '2'],\n",
       "       ['salam', '1'],\n",
       "       ['sanction', '1'],\n",
       "       ['saudi', '1'],\n",
       "       ['sbu', '5'],\n",
       "       ['secretariat', '1'],\n",
       "       ['secur', '1'],\n",
       "       ['see', '2'],\n",
       "       ['send', '1'],\n",
       "       ['sensit', '2'],\n",
       "       ['sent', '2'],\n",
       "       ['sesstatesgovgov', '1'],\n",
       "       ['side', '1'],\n",
       "       ['snc', '2'],\n",
       "       ['sporad', '1'],\n",
       "       ['spot', '3'],\n",
       "       ['state', '5'],\n",
       "       ['stategov', '1'],\n",
       "       ['subject', '3'],\n",
       "       ['sullivan', '2'],\n",
       "       ['sullivanjj', '1'],\n",
       "       ['sunday', '3'],\n",
       "       ['sunni', '1'],\n",
       "       ['support', '5'],\n",
       "       ['syg', '2'],\n",
       "       ['syria', '7'],\n",
       "       ['syrian', '9'],\n",
       "       ['thing', '1'],\n",
       "       ['tighten', '1'],\n",
       "       ['tunisia', '2'],\n",
       "       ['tunisian', '1'],\n",
       "       ['turkey', '2'],\n",
       "       ['turn', '1'],\n",
       "       ['u', '4'],\n",
       "       ['unal', '2'],\n",
       "       ['unclassifi', '4'],\n",
       "       ['unit', '1'],\n",
       "       ['unsc', '1'],\n",
       "       ['updat', '1'],\n",
       "       ['urg', '2'],\n",
       "       ['us', '2'],\n",
       "       ['video', '1'],\n",
       "       ['violenc', '1'],\n",
       "       ['websit', '1'],\n",
       "       ['welcom', '1'],\n",
       "       ['would', '3']],\n",
       "      dtype='<U21')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "email     = read_txt('res/email.txt')\n",
    "# word_list = [x for x in sorted(set(email)) if len(x) % 2 == 0]\n",
    "\n",
    "# Using numpy this time for a corpus that is expandable\n",
    "np.c_[np.unique(email, return_counts=True)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PlaintextCorpusReader' object has no attribute 'demo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3582890c09c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# print(email)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nltk/corpus/__init__.py\u001b[0m in \u001b[0;36mdemo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;31m# This is out-of-date:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0mbrown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;31m#    chat80.demo()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PlaintextCorpusReader' object has no attribute 'demo'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Maakt een word_list die simpelweg alle woorden bevat die \n",
    "# een evental aan karakters hebben\n",
    "email     = read_txt('res/email.txt')\n",
    "word_list = [x for x in sorted(set(email)) if len(x) % 2 == 0]\n",
    "generate_csv_from_array(\"word_list\", word_list)\n",
    "\n",
    "# Maakt een feature_list met woorden die met een c beginnen\n",
    "starts_with_c = [x for x in word_list if x[0] == 'c']\n",
    "generate_csv_from_array(\"starts_with_c\", starts_with_c)\n",
    "\n",
    "# Maakt een feature_list met woorden die met een m beginnen\n",
    "starts_with_m = [x for x in word_list if x[0] == 'm']\n",
    "generate_csv_from_array(\"starts_with_m\", starts_with_m)\n",
    "\n",
    "# print(email)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3.2 Formule score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fuzzy Logic Toolbox implementeren\n",
    "\n",
    "    ~Peter Heemskerk\n",
    "    \n",
    "Er moet een systeem geschreven worden die de basis vormt voor het classificeren van meerdere emails, waarbij een overzicht van de classificatie en analyse van de correct en fout geclassificeerde emails wordt getoond.\n",
    "\n",
    "#### 4.1 Klassen Toevoegen Uit De Oefen Lab\n",
    "\n",
    "... leg uit wat je doet in deze stap ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
