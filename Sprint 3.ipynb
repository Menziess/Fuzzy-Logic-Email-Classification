{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 3\n",
    "\n",
    "In de [derde sprint](https://trello.com/b/EUxZhLuE/sprint-3-milestone-1-27-nov) werken we aan de volgende taken:\n",
    "\n",
    "1. [Helper Functions](#1.-Helper-Functions)\n",
    "2. [Top Layer van het Systeem](#2.-Top-Layer-van-het-Systeem) ~Jim\n",
    "3. [Feature score berekenen van woorden, feature vectors maken](#3.-Feature-score-berekenen-van-woorden,-feature-vectors-maken) ~Stefan\n",
    "4. [Fuzzy Logic Toolbox implementeren](#4.-Fuzzy-Logic-Toolbox-implementeren) ~Peter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Helper Functions\n",
    "\n",
    "In [Sprint 2](http://localhost:8888/notebooks/Sprint%202.ipynb) hebben we methodes gemaakt om woorden te tellen en een intersectie tussen woordenlijsten uit te voeren. Deze methodes kunnen worden gebruikt bij de taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/stefan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/stefan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def tokenize(body):\n",
    "    tokens = word_tokenize(body)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    porter = PorterStemmer()\n",
    "    words = [porter.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "def read_txt(filepath):\n",
    "    with open(filepath, 'r') as t:\n",
    "        body = t.read()\n",
    "        return tokenize(body)\n",
    "    \n",
    "def read_csv(filepath):\n",
    "    with open(filepath, 'r') as c:\n",
    "        reader = csv.reader(c, delimiter=',')\n",
    "        for row in reader:\n",
    "            return row\n",
    "\n",
    "def generate_csv_from_array(filename, array):\n",
    "    with open(\"res/\" + filename + \".csv\", 'w', newline='') as c:\n",
    "        writer = csv.writer(c, delimiter=',')\n",
    "        writer.writerow(array)\n",
    "        \n",
    "def intersection(array1, array2):\n",
    "    \"\"\"Returns a generator, use next(generator)\"\"\"\n",
    "    return (i for i in array1 if i in array2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Top Layer van het Systeem\n",
    "    ~Jim Kamans\n",
    "\n",
    "Er moet een systeem geschreven worden (gedurende alle sprints) die de basis vormt voor het classificeren van meerdere emails, waarbij een overzicht van de classificatie en analyse van de correct en fout geclassificeerde emails wordt getoond.\n",
    "\n",
    "#### 2.1 Inlezen meerdere emails uit folder\n",
    "\n",
    "... leg uit wat je doet in deze stap ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature score berekenen van woorden, feature vectors maken\n",
    "\n",
    "    ~Stefan Schenk\n",
    "    \n",
    "Woorden in een corpus moeten extra features krijgen, namelijk de scores van de mate waarbij ieder woord bij een feature past. Daarna moet de algehele score van alle woorden bij elkaar worden berekend. Dit zullen de inputs zijn voor het Fuzzy Logic Systeem.\n",
    "\n",
    "#### 3.1 Generating Word List\n",
    "\n",
    "We genereren een word_list, die normaal gesproken alle relevante woorden bevat. Daarnaast genereren we twee lijsten: C en M, die de Features voorstellen (lijsten van woorden met dezelfde karakterastieken). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMAIL: ['abdel', 'abstorsv', 'aid', 'al', 'al', 'al', 'al', 'al', 'al', 'al']\n",
      "WORD_LIST: ['abstorsv', 'al', 'alfais', 'also', 'alzawahiri', 'approv', 'aq', 'arab', 'area', 'asad']\n",
      "C: ['call', 'case', 'ceasefir', 'center', 'classifi', 'commun', 'cooper']\n",
      "M: ['mail', 'mainli', 'materi', 'meet', 'minist', 'muslim']\n"
     ]
    }
   ],
   "source": [
    "email     = sorted(read_txt('res/email.txt'))\n",
    "word_list = [x for x in sorted(set(email)) if len(x) % 2 == 0]\n",
    "generate_csv_from_array(\"word_list\", word_list)\n",
    "\n",
    "print(\"EMAIL:\", email[:10])\n",
    "print(\"WORD_LIST:\", word_list[:10])\n",
    "\n",
    "# Maakt een feature_list met woorden die met een c beginnen\n",
    "starts_with_c = [x for x in word_list if x[0] == 'c']\n",
    "generate_csv_from_array(\"starts_with_c\", starts_with_c)\n",
    "\n",
    "print(\"C:\", starts_with_c[:10])\n",
    "\n",
    "# Maakt een feature_list met woorden die met een m beginnen\n",
    "starts_with_m = [x for x in word_list if x[0] == 'm']\n",
    "generate_csv_from_array(\"starts_with_m\", starts_with_m)\n",
    "\n",
    "print(\"M:\", starts_with_m[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Generating Corpus\n",
    "\n",
    "In de vorige sprint gebruikten wij de Counter class om distincte woorden te tellen en op te slaan in een dictionary. Jammergenoeg is het lastig om dictionaries uit te breiden met meerdere values.\n",
    "\n",
    "Numpy heeft een methode \"unique\" waarmee hetzelfde doel kan worden bereikt. De values en counts worden opgeslagen in een uitbreidbare np.array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['abdel' '1']\n",
      " ['abstorsv' '1']\n",
      " ['aid' '1']\n",
      " ['al' '7']\n",
      " ['alarabi' '1']\n",
      " ['alfais' '1']\n",
      " ['alqaida' '1']\n",
      " ['also' '1']\n",
      " ['althani' '1']\n",
      " ['alzawahiri' '3']]\n"
     ]
    }
   ],
   "source": [
    "def corpus(word_array):\n",
    "    return np.c_[np.unique(email, return_counts=True)]\n",
    "\n",
    "corpus = corpus(email)\n",
    "\n",
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Formule Score\n",
    "\n",
    "Als laatst worden de scores berekend voor alle woorden, voor alle Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 2, 1, 1, 1, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def intersect(corpus, feature_list):\n",
    "    return ( x for x in corpus if x[0] in feature_list ) \n",
    "\n",
    "# Creates two generators that iterate results of intersection\n",
    "feature1 = intersect(corpus, starts_with_c)\n",
    "feature2 = intersect(corpus, starts_with_m)\n",
    "\n",
    "# Once a generator is used, it returns empty results\n",
    "[int(i[1]) for i in feature1])\n",
    "sum([int(i[1]) for i in feature1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fuzzy Logic Toolbox implementeren\n",
    "\n",
    "    ~Peter Heemskerk\n",
    "    \n",
    "Er moet een systeem geschreven worden die de basis vormt voor het classificeren van meerdere emails, waarbij een overzicht van de classificatie en analyse van de correct en fout geclassificeerde emails wordt getoond.\n",
    "\n",
    "#### 4.1 Klassen Toevoegen Uit De Oefen Lab\n",
    "\n",
    "... leg uit wat je doet in deze stap ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
