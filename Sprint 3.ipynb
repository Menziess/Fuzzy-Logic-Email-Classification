{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 3\n",
    "\n",
    "In de [derde sprint](https://trello.com/b/EUxZhLuE/sprint-3-milestone-1-27-nov) werken we aan de volgende taken:\n",
    "\n",
    "1. [Helper Functions](http://localhost:8888/notebooks/Sprint%203.ipynb#Helper-Functions)\n",
    "2. [Top Layer van het Systeem](http://localhost:8888/notebooks/Sprint%203.ipynb#1.-Top-Layer-van-het-Systeem) ~Jim\n",
    "3. [Feature score berekenen van woorden, feature vectors maken](http://localhost:8888/notebooks/Sprint%203.ipynb#2.-Feature-score-berekenen-van-woorden,-feature-vectors-maken) ~Stefan\n",
    "4. [Fuzzy Logic Toolbox implementeren]() ~Peter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Helper Functions\n",
    "\n",
    "In [Sprint 2](http://localhost:8888/notebooks/Sprint%202.ipynb) hebben we methodes gemaakt om woorden te tellen en een intersectie tussen woordenlijsten uit te voeren. Deze methodes kunnen worden gebruikt bij de taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/stefan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/stefan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def tokenize(body):\n",
    "    tokens = word_tokenize(body)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    porter = PorterStemmer()\n",
    "    words = [porter.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "def read_txt(filepath):\n",
    "    with open(filepath, 'r') as t:\n",
    "        body = t.read()\n",
    "        return tokenize(body)\n",
    "    \n",
    "def read_csv(filepath):\n",
    "    with open(filepath, 'r') as c:\n",
    "        reader = csv.reader(c, delimiter=',')\n",
    "        for row in reader:\n",
    "            return row\n",
    "\n",
    "def generate_csv_from_array(filename, array):\n",
    "    with open(\"res/\" + filename + \".csv\", 'w', newline='') as c:\n",
    "        writer = csv.writer(c, delimiter=',')\n",
    "        writer.writerow(array)\n",
    "        \n",
    "def intersection(array1, array2):\n",
    "    \"\"\"Returns a generator, use next(generator)\"\"\"\n",
    "    return (i for i in array1 if i in array2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Top Layer van het Systeem\n",
    "    ~Jim Kamans\n",
    "\n",
    "Er moet een systeem geschreven worden (gedurende alle sprints) die de basis vormt voor het classificeren van meerdere emails, waarbij een overzicht van de classificatie en analyse van de correct en fout geclassificeerde emails wordt getoond.\n",
    "\n",
    "#### 2.1 Inlezen meerdere emails uit folder\n",
    "\n",
    "... leg uit wat je doet in deze stap ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature score berekenen van woorden, feature vectors maken\n",
    "\n",
    "    ~Stefan Schenk\n",
    "    \n",
    "Woorden in een corpus moeten extra features krijgen, namelijk de scores van de mate waarbij ieder woord bij een feature past. Daarna moet de algehele score van alle woorden bij elkaar worden berekend. Dit zullen de inputs zijn voor het Fuzzy Logic Systeem.\n",
    "\n",
    "#### 3.1 Generating Word List\n",
    "\n",
    "... leg uit wat je doet in deze stap ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maakt een word_list die simpelweg alle woorden bevat die \n",
    "# een evental aan karakters hebben\n",
    "email     = read_txt('res/email.txt')\n",
    "word_list = [x for x in sorted(set(email)) if len(x) % 2 == 0]\n",
    "generate_csv_from_array(\"word_list\", word_list)\n",
    "\n",
    "# Maakt een feature_list met woorden die met een c beginnen\n",
    "starts_with_c = [x for x in word_list if x[0] == 'c']\n",
    "generate_csv_from_array(\"starts_with_c\", starts_with_c)\n",
    "\n",
    "# Maakt een feature_list met woorden die met een m beginnen\n",
    "starts_with_m = [x for x in word_list if x[0] == 'm']\n",
    "generate_csv_from_array(\"starts_with_m\", starts_with_m)\n",
    "\n",
    "# print(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fuzzy Logic Toolbox implementeren\n",
    "\n",
    "    ~Peter Heemskerk\n",
    "    \n",
    "Er moet een systeem geschreven worden die de basis vormt voor het classificeren van meerdere emails, waarbij een overzicht van de classificatie en analyse van de correct en fout geclassificeerde emails wordt getoond.\n",
    "\n",
    "#### 4.1 Klassen Toevoegen Uit De Oefen Lab\n",
    "\n",
    "... leg uit wat je doet in deze stap ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
