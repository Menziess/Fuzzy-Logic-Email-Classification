{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 3\n",
    "\n",
    "In de [derde sprint](https://trello.com/b/EUxZhLuE/sprint-3-milestone-1-27-nov) werken we aan de volgende taken:\n",
    "\n",
    "1. [Helper Functions](#1.-Helper-Functions)\n",
    "2. [Top Layer van het Systeem](#2.-Top-Layer-van-het-Systeem) ~Jim\n",
    "3. [Feature score berekenen van woorden, feature vectors maken](#3.-Feature-score-berekenen-van-woorden,-feature-vectors-maken) ~Stefan\n",
    "4. [Fuzzy Logic Toolbox implementeren](#4.-Fuzzy-Logic-Toolbox-implementeren) ~Peter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Helper Functions\n",
    "\n",
    "In [Sprint 2](http://localhost:8888/notebooks/Sprint%202.ipynb) hebben we methodes gemaakt om woorden te tellen en een intersectie tussen woordenlijsten uit te voeren. Deze methodes kunnen worden gebruikt bij de taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def tokenize(body):\n",
    "    tokens = word_tokenize(body)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    porter = PorterStemmer()\n",
    "    words = [porter.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "def read_txt(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        body = t.read()\n",
    "    return tokenize(body)     \n",
    "    \n",
    "def read_csv(filepath):\n",
    "    with open(filepath, 'r') as c:\n",
    "        reader = csv.reader(c, delimiter=',')\n",
    "        for row in reader:\n",
    "            return row\n",
    "\n",
    "def generate_csv_from_array(filename, array):\n",
    "    with open(\"res/\" + filename + \".csv\", 'w', newline='') as c:\n",
    "        writer = csv.writer(c, delimiter=',')\n",
    "        writer.writerow(array)\n",
    "        \n",
    "def intersection(array1, array2):\n",
    "    \"\"\"Returns a generator, use next(generator)\"\"\"\n",
    "    return (i for i in array1 if i in array2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Top Layer van het Systeem\n",
    "    ~Jim Kamans\n",
    "\n",
    "Er moet een systeem geschreven worden (gedurende alle sprints) die de basis vormt voor het classificeren van meerdere emails, waarbij een overzicht van de classificatie en analyse van de correct en fout geclassificeerde emails wordt getoond.\n",
    "\n",
    "#### 2.1 Inlezen meerdere emails uit folder\n",
    "\n",
    "We zoeken in het path van de dataset naar alle emails van alle employees (in get_emails()). Deze lezen we in met read_email(), welke een tokenized list returned.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No all_documents folder: blair-l\n",
      "['paula', 'million', 'fine', 'phillip']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['brenda', 'pleas', 'use', 'second', 'check', 'octob', 'payment', 'alreadi', 'toss', 'let', 'know', 'mail', 'anoth', 'phillip']\n",
      "['think', 'fletch', 'good', 'cpa', 'still']\n",
      "['brenda', 'pleas', 'use', 'second', 'check', 'octob', 'payment', 'copi', 'origin', 'deal', 'want', 'fax', 'phillip']\n",
      "['sacramento', 'correspond', 'exit', 'news', 'confer', 'gov', 'davi', 'ferc', 'chair', 'hoecker', 'doe', 'sectretari', 'richardson', 'other', 'outlin', 'sever', 'emerg', 'measur', 'includ', 'westwid', 'price', 'cap', 'soon', 'report', 'file', 'send', 'attent', 'expect', 'around', 'pm']\n",
      "[]\n",
      "['lian', 'discuss', 'yesterday', 'concern', 'attempt', 'manipul', 'el', 'paso', 'san', 'juan', 'monthli', 'index', 'singl', 'buyer', 'enter', 'marketplac', 'septemb', 'paid', 'market', 'price', 'san', 'juan', 'ga', 'intent', 'distort', 'index', 'time', 'trade', 'offer', 'physic', 'ga', 'significantli', 'cent', 'lower', 'price', 'bypass', 'order', 'establish', 'higher', 'trade', 'report', 'index', 'calcul', 'addit', 'trade', 'line', 'associ', 'financi', 'swap', 'san', 'juan', 'compil', 'list', 'financi', 'physic', 'trade', 'execut', 'septemb', 'septemb', 'complet', 'list', 'trade', 'enron', 'onlin', 'eol', 'enron', 'direct', 'phone', 'convers', 'three', 'brokerag', 'firm', 'amerex', 'apb', 'prebon', 'pleas', 'see', 'attach', 'spreadsheet', 'trade', 'trade', 'list', 'summari', 'also', 'includ', 'summari', 'ga', 'daili', 'price', 'illustr', 'valu', 'san', 'juan', 'base', 'sever', 'spread', 'relationship', 'two', 'key', 'point', 'data', 'follow', 'high', 'physic', 'price', 'much', 'greater', 'high', 'financi', 'trade', 'day', 'spread', 'relationship', 'san', 'juan', 'point', 'socal', 'northwest', 'consist', 'end', 'septemb', 'octob', 'ga', 'daili', 'nt', 'make', 'sens', 'monthli', 'indec', 'dramat', 'differ', 'understand', 'review', 'trade', 'submit', 'outlier', 'hope', 'trade', 'submit', 'reveal', 'counterparti', 'name', 'abl', 'determin', 'one', 'buyer', 'trade', 'outlier', 'want', 'give', 'addit', 'point', 'refer', 'aid', 'establish', 'reason', 'index', 'enron', 'belief', 'trade', 'higher', 'market', 'trade', 'exclud', 'calcul', 'index', 'desir', 'reliabl', 'accur', 'indec', 'conduct', 'physic', 'financi', 'busi', 'pleas', 'contact', 'anytim', 'assist', 'toward', 'goal', 'sincer', 'phillip', 'allen']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['outlook',\n",
       " 'migrat',\n",
       " 'team',\n",
       " 'enron',\n",
       " 'pm',\n",
       " 'wilchynskihrcorpenron',\n",
       " 'enron',\n",
       " 'cindi',\n",
       " 'r',\n",
       " 'wardnaenron',\n",
       " 'enron',\n",
       " 'j',\n",
       " 'ann',\n",
       " 'hillcorpenron',\n",
       " 'enron',\n",
       " 'sonja',\n",
       " 'gallowaycorpenron',\n",
       " 'enron',\n",
       " 'bilal',\n",
       " 'bajwan',\n",
       " 'aenron',\n",
       " 'enron',\n",
       " 'binh',\n",
       " 'phamhouect',\n",
       " 'ect',\n",
       " 'bradley',\n",
       " 'jonesenron',\n",
       " 'enronxg',\n",
       " 'bruce',\n",
       " 'millscorpenron',\n",
       " 'enron',\n",
       " 'chanc',\n",
       " 'rabonenron',\n",
       " 'enronxg',\n",
       " 'chuck',\n",
       " 'amesnaenron',\n",
       " 'enron',\n",
       " 'david',\n",
       " 'baumbachhouect',\n",
       " 'ect',\n",
       " 'jad',\n",
       " 'doanenron',\n",
       " 'enronxg',\n",
       " 'oneal',\n",
       " 'win',\n",
       " 'freehouect',\n",
       " 'ect',\n",
       " 'phillip',\n",
       " 'lovehouect',\n",
       " 'ect',\n",
       " 'sladanaanna',\n",
       " 'kulicenron',\n",
       " 'enro',\n",
       " 'nxgate',\n",
       " 'victor',\n",
       " 'guggenheimhouect',\n",
       " 'ect',\n",
       " 'alejandra',\n",
       " 'chaveznaenron',\n",
       " 'enron',\n",
       " 'ann',\n",
       " 'e',\n",
       " 'bikeenron',\n",
       " 'enronxg',\n",
       " 'carol',\n",
       " 'franknaenron',\n",
       " 'enron',\n",
       " 'darron',\n",
       " 'c',\n",
       " 'gironhouec',\n",
       " 'ect',\n",
       " 'elizabeth',\n",
       " 'l',\n",
       " 'hernandezhouect',\n",
       " 'ect',\n",
       " 'elizabeth',\n",
       " 'shimcorpenron',\n",
       " 'enron',\n",
       " 'jeff',\n",
       " 'royedcorpenron',\n",
       " 'enron',\n",
       " 'kam',\n",
       " 'keiserhouect',\n",
       " 'ect',\n",
       " 'kimat',\n",
       " 'singlahouect',\n",
       " 'e',\n",
       " 'ct',\n",
       " 'kristen',\n",
       " 'clauseenron',\n",
       " 'enronxg',\n",
       " 'kulvind',\n",
       " 'fowlernaenron',\n",
       " 'enron',\n",
       " 'kyle',\n",
       " 'r',\n",
       " 'lillyhouect',\n",
       " 'ect',\n",
       " 'lucha',\n",
       " 'johnsonnaenron',\n",
       " 'enron',\n",
       " 'maria',\n",
       " 'garzahouect',\n",
       " 'ect',\n",
       " 'patrick',\n",
       " 'rydernaenron',\n",
       " 'enron',\n",
       " 'ryan',\n",
       " 'orourkeenron',\n",
       " 'enronxg',\n",
       " 'yuan',\n",
       " 'tiann',\n",
       " 'aenron',\n",
       " 'enron',\n",
       " 'frank',\n",
       " 'ermishouect',\n",
       " 'ect',\n",
       " 'jane',\n",
       " 'tholthouect',\n",
       " 'ect',\n",
       " 'jay',\n",
       " 'reitm',\n",
       " 'eyerhouect',\n",
       " 'ect',\n",
       " 'keith',\n",
       " 'holsthouect',\n",
       " 'ect',\n",
       " 'matthew',\n",
       " 'lenharthouect',\n",
       " 'ect',\n",
       " 'mik',\n",
       " 'e',\n",
       " 'grigsbyhouect',\n",
       " 'ect',\n",
       " 'moniqu',\n",
       " 'sanchezhouect',\n",
       " 'ect',\n",
       " 'phillip',\n",
       " 'k',\n",
       " 'allenhouect',\n",
       " 'ect',\n",
       " 'randal',\n",
       " 'l',\n",
       " 'gayhouect',\n",
       " 'ect',\n",
       " 'tori',\n",
       " 'kuykendallhouect',\n",
       " 'ect',\n",
       " 'ina',\n",
       " 'normanho',\n",
       " 'uect',\n",
       " 'ect',\n",
       " 'jacki',\n",
       " 'travishouect',\n",
       " 'ect',\n",
       " 'michael',\n",
       " 'j',\n",
       " 'gasperhouect',\n",
       " 'ect',\n",
       " 'brenda',\n",
       " 'h',\n",
       " 'fletcherhouect',\n",
       " 'ect',\n",
       " 'jeann',\n",
       " 'wukaschcorpenron',\n",
       " 'enron',\n",
       " 'mari',\n",
       " 'theresa',\n",
       " 'frank',\n",
       " 'linhouect',\n",
       " 'ect',\n",
       " 'mike',\n",
       " 'potternaenron',\n",
       " 'enron',\n",
       " 'natali',\n",
       " 'bakerhouect',\n",
       " 'ect',\n",
       " 'suz',\n",
       " 'ann',\n",
       " 'calcagnonaenron',\n",
       " 'enron',\n",
       " 'albert',\n",
       " 'stromquistcorpenron',\n",
       " 'enron',\n",
       " 'rajesh',\n",
       " 'ch',\n",
       " 'ettiarenrondevelop',\n",
       " 'enrondevelop',\n",
       " 'derek',\n",
       " 'andersonhouect',\n",
       " 'ect',\n",
       " 'bra',\n",
       " 'hornhouect',\n",
       " 'ect',\n",
       " 'camil',\n",
       " 'gerardcorpenron',\n",
       " 'enron',\n",
       " 'cathi',\n",
       " 'liranaenron',\n",
       " 'en',\n",
       " 'ron',\n",
       " 'daniel',\n",
       " 'castagnolaenrondevelop',\n",
       " 'enrondevelop',\n",
       " 'eva',\n",
       " 'towcorpen',\n",
       " 'ron',\n",
       " 'enron',\n",
       " 'lam',\n",
       " 'nguyennaenron',\n",
       " 'enron',\n",
       " 'andi',\n",
       " 'pacenaenron',\n",
       " 'enron',\n",
       " 'anna',\n",
       " 'santuc',\n",
       " 'cinaenron',\n",
       " 'enron',\n",
       " 'claudia',\n",
       " 'guerranaenron',\n",
       " 'enron',\n",
       " 'clayton',\n",
       " 'vernoncorpenron',\n",
       " 'enron',\n",
       " 'david',\n",
       " 'ryancorpenron',\n",
       " 'enron',\n",
       " 'eric',\n",
       " 'smithcontractorenron',\n",
       " 'communicat',\n",
       " 'ion',\n",
       " 'enron',\n",
       " 'commun',\n",
       " 'grace',\n",
       " 'kimnaenron',\n",
       " 'enron',\n",
       " 'jason',\n",
       " 'kanissenron',\n",
       " 'enr',\n",
       " 'onxgat',\n",
       " 'kevin',\n",
       " 'clinecorpenron',\n",
       " 'enron',\n",
       " 'rika',\n",
       " 'imainaenron',\n",
       " 'enron',\n",
       " 'todd',\n",
       " 'decoo',\n",
       " 'kcorpenron',\n",
       " 'enron',\n",
       " 'beth',\n",
       " 'jensennpngenron',\n",
       " 'enron',\n",
       " 'billi',\n",
       " 'harrillnpngenron',\n",
       " 'enron',\n",
       " 'martha',\n",
       " 'sumnerkenneynpngenron',\n",
       " 'enron',\n",
       " 'phylli',\n",
       " 'millernpngenron',\n",
       " 'enr',\n",
       " 'sandi',\n",
       " 'olofsonnpngenron',\n",
       " 'enron',\n",
       " 'theresa',\n",
       " 'byrnenpngenron',\n",
       " 'enron',\n",
       " 'danni',\n",
       " 'ccartyet',\n",
       " 'senron',\n",
       " 'enron',\n",
       " 'deni',\n",
       " 'tufgtenron',\n",
       " 'enron',\n",
       " 'john',\n",
       " 'ayresfgtenron',\n",
       " 'e',\n",
       " 'nron',\n",
       " 'john',\n",
       " 'millarfgtenron',\n",
       " 'enron',\n",
       " 'juli',\n",
       " 'armstrongcorpenron',\n",
       " 'enron',\n",
       " 'maggi',\n",
       " 'schroederfgtenron',\n",
       " 'enron',\n",
       " 'max',\n",
       " 'brownotsenron',\n",
       " 'enron',\n",
       " 'randi',\n",
       " 'cantrellgco',\n",
       " 'nron',\n",
       " 'enron',\n",
       " 'traci',\n",
       " 'scottcorpenron',\n",
       " 'enron',\n",
       " 'charl',\n",
       " 'muzzyhouect',\n",
       " 'ect',\n",
       " 'cora',\n",
       " 'pendergrasscorpenron',\n",
       " 'enron',\n",
       " 'darren',\n",
       " 'espeycorpenron',\n",
       " 'enron',\n",
       " 'jessica',\n",
       " 'white',\n",
       " 'naenron',\n",
       " 'enron',\n",
       " 'kevin',\n",
       " 'bradynaenron',\n",
       " 'enron',\n",
       " 'kirk',\n",
       " 'lenarthouect',\n",
       " 'ect',\n",
       " 'lisa',\n",
       " 'kinseyhouect',\n",
       " 'ect',\n",
       " 'margi',\n",
       " 'straighthouect',\n",
       " 'ect',\n",
       " 'mark',\n",
       " 'l',\n",
       " 'schrabhouect',\n",
       " 'ect',\n",
       " 'souad',\n",
       " 'mahmassanicorpenron',\n",
       " 'enron',\n",
       " 'tammi',\n",
       " 'gilmorenaenron',\n",
       " 'enron',\n",
       " 'teresa',\n",
       " 'mc',\n",
       " 'ombernaenron',\n",
       " 'enron',\n",
       " 'we',\n",
       " 'dempseynaenron',\n",
       " 'enron',\n",
       " 'barri',\n",
       " 'feldmannycmgusa',\n",
       " 'gusa',\n",
       " 'catherin',\n",
       " 'huynhnaenron',\n",
       " 'enron',\n",
       " 'cc',\n",
       " 'subject',\n",
       " 'surveyinform',\n",
       " 'email',\n",
       " 'current',\n",
       " 'note',\n",
       " 'user',\n",
       " 'ensur',\n",
       " 'experi',\n",
       " 'success',\n",
       " 'migrat',\n",
       " 'note',\n",
       " 'outlook',\n",
       " 'necessari',\n",
       " 'gather',\n",
       " 'individu',\n",
       " 'user',\n",
       " 'inform',\n",
       " 'prior',\n",
       " 'date',\n",
       " 'f',\n",
       " 'migrat',\n",
       " 'pleas',\n",
       " 'take',\n",
       " 'minut',\n",
       " 'complet',\n",
       " 'fill',\n",
       " 'followin',\n",
       " 'g',\n",
       " 'survey',\n",
       " 'doubl',\n",
       " 'click',\n",
       " 'document',\n",
       " 'put',\n",
       " 'edit',\n",
       " 'mode',\n",
       " 'fini',\n",
       " 'h',\n",
       " 'simpli',\n",
       " 'click',\n",
       " 'repli',\n",
       " 'histori',\n",
       " 'button',\n",
       " 'hit',\n",
       " 'send',\n",
       " 'su',\n",
       " 'rvey',\n",
       " 'automat',\n",
       " 'sent',\n",
       " 'outlook',\n",
       " 'migrat',\n",
       " 'mailbox',\n",
       " 'thank',\n",
       " 'outlook',\n",
       " 'migrat',\n",
       " 'team',\n",
       " 'full',\n",
       " 'name',\n",
       " 'phillip',\n",
       " 'login',\n",
       " 'id',\n",
       " 'extens',\n",
       " 'offic',\n",
       " 'locat',\n",
       " 'type',\n",
       " 'comput',\n",
       " 'desktop',\n",
       " 'laptop',\n",
       " 'pda',\n",
       " 'ye',\n",
       " 'type',\n",
       " 'none',\n",
       " 'ipaq',\n",
       " 'palm',\n",
       " 'pilo',\n",
       " 'jornada',\n",
       " 'ipaq',\n",
       " 'permiss',\n",
       " 'access',\n",
       " 'anyon',\n",
       " 'emailcalendar',\n",
       " 'ye',\n",
       " 'anyon',\n",
       " 'permiss',\n",
       " 'access',\n",
       " 'emailcalendar',\n",
       " 'ina',\n",
       " 'ran',\n",
       " 'gel',\n",
       " 'ye',\n",
       " 'respons',\n",
       " 'updat',\n",
       " 'anyon',\n",
       " 'els',\n",
       " 'address',\n",
       " 'book',\n",
       " 'ye',\n",
       " 'anyon',\n",
       " 'els',\n",
       " 'respons',\n",
       " 'updat',\n",
       " 'address',\n",
       " 'book',\n",
       " 'ye',\n",
       " 'access',\n",
       " 'share',\n",
       " 'calendar',\n",
       " 'ye',\n",
       " 'share',\n",
       " 'calendar',\n",
       " 'distribut',\n",
       " 'group',\n",
       " 'messag',\n",
       " 'maintain',\n",
       " 'ass',\n",
       " 'mail',\n",
       " 'ye',\n",
       " 'pleas',\n",
       " 'list',\n",
       " 'pleas',\n",
       " 'list',\n",
       " 'note',\n",
       " 'databas',\n",
       " 'applic',\n",
       " 'current',\n",
       " 'use',\n",
       " 'effort',\n",
       " 'plan',\n",
       " 'exact',\n",
       " 'datetim',\n",
       " 'migrat',\n",
       " 'also',\n",
       " 'need',\n",
       " 'know',\n",
       " 'normal',\n",
       " 'work',\n",
       " 'hour',\n",
       " 'offic',\n",
       " 'near',\n",
       " 'futur',\n",
       " 'vacat',\n",
       " 'leav',\n",
       " 'etc',\n",
       " 'mmddyy',\n",
       " 'mmddyy']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def read_email(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        text = \"\"\n",
    "        reading = False\n",
    "        \n",
    "        # start reading email after the first blank line (so crap like x-header etc is gone)\n",
    "        # stop reading when a \"forwarded part\" is encountered\n",
    "        for line in file:\n",
    "            if reading:\n",
    "                if \"---- forwarded\" in line.lower(): \n",
    "                    break\n",
    "                text += line\n",
    "            else:\n",
    "                if line in ['\\n','\\r\\n']:\n",
    "                    reading = True\n",
    "    return tokenize(text)\n",
    "\n",
    "def get_emails():\n",
    "    path_of_dataset = \"../_email/enron_mail_20150507/maildir\"\n",
    "    mail_folder = \"all_documents\"\n",
    "    employees = listdir(path_of_dataset)  \n",
    "    emails = []\n",
    "    \n",
    "    for employee in employees[:10]:\n",
    "#     for employee in employees:\n",
    "        path_to_emails = path_of_dataset + \"/\" + employee + \"/\" + mail_folder\n",
    "        try:\n",
    "            emails += [(path_to_emails + \"/\" + f) for f in listdir(path_to_emails) if f.endswith(\".\")]\n",
    "        except:\n",
    "            print(\"No {} folder:\".format(mail_folder), employee)\n",
    "            pass\n",
    "\n",
    "    return emails\n",
    "\n",
    "emails = get_emails()\n",
    "for email in emails[5:15]:\n",
    "    tokens = read_txt(email)\n",
    "    print(tokens)\n",
    "\n",
    "# read_txt(\"../_email/enron_mail_20150507/maildir/allen-p/_sent_mail/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature score berekenen van woorden, feature vectors maken\n",
    "\n",
    "    ~Stefan Schenk\n",
    "    \n",
    "Woorden in een corpus moeten extra features krijgen, namelijk de scores van de mate waarbij ieder woord bij een feature past. Daarna moet de algehele score van alle woorden bij elkaar worden berekend. Dit zullen de inputs zijn voor het Fuzzy Logic Systeem.\n",
    "\n",
    "#### 3.1 Generating Word List\n",
    "\n",
    "We genereren een word_list, die normaal gesproken alle relevante woorden bevat. Daarnaast genereren we twee lijsten: C en M, die de Features voorstellen (lijsten van woorden met dezelfde karakterastieken). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMAIL: ['abdel', 'abstorsv', 'aid', 'al', 'al', 'al', 'al', 'al', 'al', 'al']\n",
      "C: ['cairo', 'cairo', 'cairo', 'cairo', 'cairo', 'cairo', 'call', 'call', 'call', 'case']\n",
      "M: ['mail', 'mail', 'mainli', 'materi', 'meet', 'meet', 'middl', 'minist', 'minist', 'minist']\n",
      "WORD_LIST: ['cairo', 'cairo', 'cairo', 'cairo', 'cairo', 'cairo', 'call', 'call', 'call', 'case']\n"
     ]
    }
   ],
   "source": [
    "email = sorted(read_txt('res/email.txt'))\n",
    "print(\"EMAIL:\", email[:10])\n",
    "# print(\"WORD_LIST:\", word_list[:10])\n",
    "\n",
    "# Maakt een feature_list met woorden die met een c beginnen\n",
    "starts_with_c = [x for x in email if x[0] == 'c']\n",
    "generate_csv_from_array(\"starts_with_c\", starts_with_c)\n",
    "print(\"C:\", starts_with_c[:10])\n",
    "\n",
    "# Maakt een feature_list met woorden die met een m beginnen\n",
    "starts_with_m = [x for x in email if x[0] == 'm']\n",
    "generate_csv_from_array(\"starts_with_m\", starts_with_m)\n",
    "print(\"M:\", starts_with_m[:10])\n",
    "\n",
    "# Maakt de filter word_list, bestaande uit combinatie van de Features\n",
    "word_list = starts_with_c + starts_with_m\n",
    "print(\"WORD_LIST:\", word_list[:10])\n",
    "generate_csv_from_array(\"word_list\", word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Generating Corpus\n",
    "\n",
    "In de vorige sprint gebruikten wij de Counter class om distincte woorden te tellen en op te slaan in een dictionary. Jammergenoeg is het lastig om dictionaries uit te breiden met meerdere values.\n",
    "\n",
    "Numpy heeft een methode \"unique\" waarmee hetzelfde doel kan worden bereikt. De values en counts worden opgeslagen in een uitbreidbare np.array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cairo' '6']\n",
      " ['call' '3']\n",
      " ['case' '2']\n",
      " ['ceasefir' '2']\n",
      " ['center' '1']\n",
      " ['cia' '1']\n",
      " ['classifi' '1']\n",
      " ['clear' '1']\n",
      " ['clinton' '1']\n",
      " ['comment' '3']]\n"
     ]
    }
   ],
   "source": [
    "def corpus(email, word_list):\n",
    "    words = [x for x in intersection(email, word_list)]\n",
    "    return np.c_[np.unique(words, return_counts=True)]\n",
    "\n",
    "print(corpus(email, word_list)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Formule Score\n",
    "\n",
    "Als laatst worden de scores berekend voor alle woorden, voor alle Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RATING:\n",
      " [['cairo' '6' '0.2143' '0.0']\n",
      " ['call' '3' '0.1071' '0.0']\n",
      " ['case' '2' '0.0714' '0.0']\n",
      " ['ceasefir' '2' '0.0714' '0.0']\n",
      " ['center' '1' '0.0357' '0.0']\n",
      " ['cia' '1' '0.0357' '0.0']\n",
      " ['classifi' '1' '0.0357' '0.0']\n",
      " ['clear' '1' '0.0357' '0.0']\n",
      " ['clinton' '1' '0.0357' '0.0']\n",
      " ['comment' '3' '0.1071' '0.0']\n",
      " ['commun' '1' '0.0357' '0.0']\n",
      " ['contribut' '1' '0.0357' '0.0']\n",
      " ['cooper' '2' '0.0714' '0.0']\n",
      " ['council' '2' '0.0714' '0.0']\n",
      " ['countri' '1' '0.0357' '0.0']\n",
      " ['creat' '2' '0.0714' '0.0']\n",
      " ['crisiss' '1' '0.0357' '0.0']\n",
      " ['current' '1' '0.0357' '0.0']\n",
      " ['mail' '2' '0.0' '0.0714']\n",
      " ['mainli' '1' '0.0' '0.0357']\n",
      " ['materi' '1' '0.0' '0.0357']\n",
      " ['meet' '2' '0.0' '0.0714']\n",
      " ['middl' '1' '0.0' '0.0357']\n",
      " ['minist' '5' '0.0' '0.1786']\n",
      " ['mission' '2' '0.0' '0.0714']\n",
      " ['monitor' '1' '0.0' '0.0357']\n",
      " ['monitorspsembassi' '1' '0.0' '0.0357']\n",
      " ['muslim' '3' '0.0' '0.1071']]\n"
     ]
    }
   ],
   "source": [
    "def rate(corpus, feature_lists):\n",
    "    c_len = len(corpus)\n",
    "    c = corpus\n",
    "    for f in feature_lists:\n",
    "        c = np.c_[c, np.zeros(c_len)]\n",
    "        for row in c:\n",
    "            if (row[0] in f):\n",
    "                row[-1:] = round(int(row[1]) / c_len, 4)\n",
    "    return c\n",
    "\n",
    "rating = rate(\n",
    "    corpus(email, word_list), \n",
    "    [starts_with_c, starts_with_m] )\n",
    "\n",
    "print(\"RATING:\\n\", rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Aggregation Scores to Input FIS\n",
    "\n",
    "De scores worden geaggregeerd zodat zij als input voor het Fuzzy Logic Systeem kunnen dienen.\n",
    "\n",
    "$max( \\: \\sum \\frac{word_{count}}{word\\_list_{count}}, 1.0 \\: )$\n",
    "\n",
    "$\n",
    "score =\n",
    "\\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\t0  & \\mbox{if } x \\leq 0 \\\\\n",
    "        x  & \\mbox{if } \\{x \\mid 0 < x < 1\\} \\\\\n",
    "\t\t1 & \\mbox{if } x \\geq 1\n",
    "\t\\end{array}\n",
    "\\right.\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.0, 1: 0.67839999999999989}\n"
     ]
    }
   ],
   "source": [
    "def email_rating(email, feature_lists):\n",
    "    c = rate(corpus(email, word_list), feature_lists)\n",
    "    ratings = dict()\n",
    "    for i in range(len(feature_lists)):\n",
    "        ratings[i] = min((c[:,i + 2].astype(np.float).sum()), 1.0)\n",
    "    return ratings\n",
    "    \n",
    "inputs = email_rating(email, [starts_with_c, starts_with_m])\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fuzzy Logic Toolbox implementeren\n",
    "\n",
    "    ~Peter Heemskerk\n",
    "    \n",
    "Hieronder de standaard uit het LAB vrekregen code voor een fuzzy logic implementatie. De classes zijn zo gedefinieerd dat je in een aantal stappen een eenvoudige implementatie van een Fuzzy Logic systeem kunt definieren. \n",
    "\n",
    "stap a. creeer membership functie mbv. class TriangularMF of class TrapezoidalMF. \n",
    "        voorbeeld: \n",
    "            triangular_mf = TriangularMF(\"medium\", 150, 250, 350) \n",
    "stap b. creer input en output functes met class Input(Variable) of class Output(Variable). \n",
    "        voorbeeld: \n",
    "            mfs_income = [TrapezoidalMF(\"low\", -100, 0, 200, 400), TriangularMF(\"medium\", 200, 500, 800)]\n",
    "            income = Input(\"income\", (0, 1000), mfs_income)\\\n",
    "stap c. zet deze inputfuncties en outputfuncies in de lijst met inputs en outputs.\n",
    "        voorbeeld: \n",
    "            inputs = [income, quality]\n",
    "            output = money\n",
    "stap d. definieer regels middels class Rule:\n",
    "        voorbeeld: \n",
    "            rule1 = Rule(1, [\"low\", \"amazing\"], \"and\", \"low\")\n",
    "stap e. zet alle regels in een class Rulebase: \n",
    "        voorbeeld: \n",
    "            rules = [rule1, rule2, rule3, rule4, rule5, rule6, rule7, rule8, rule9]\n",
    "            rulebase = Rulebase(rules).\n",
    "stap f. je kunt nu firing strenght van deze regel oproepen: \n",
    "            rule1.calculate_firing_strength([200, 6.5], inputs), \n",
    "        en de totale firing strenghts (!):  \n",
    "            rulebase.calculate_firing_strengths(datapoint, inputs)\n",
    "stap g. creeer nu de totale fuzzy logic set middels class Reasoner\n",
    "        voorbeeld: \n",
    "            thinker = Reasoner(rulebase, inputs, output, 201, \"som\")\n",
    "stap h. je kunt nu voor een datapunt op je input een crisp/defuzzified output krijgen met de functie: \n",
    "            thinker.inference(datapoint)\n",
    "\n",
    "\n",
    "#### 4.1 Membership Functions\n",
    "\n",
    "Membership functions are used to fuzzify crisp inputs, representing an item's membership to a class, with 0 meaning no membership and 1 meaning the item is a perfect prototype of a class.\n",
    "\n",
    "During the Fuzzy Logic crash course we have seen 4 basic types of membership functions: triangular, trapezoidal, gaussian and generalized bell shaped membership functions. Those membership functions are represented in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "class TriangularMF:\n",
    "    \"\"\"Triangular fuzzy logic membership function class.\"\"\"\n",
    "    def __init__(self, name, start, top, end):\n",
    "        self.name = name\n",
    "        self.start = start\n",
    "        self.top = top\n",
    "        self.end = end\n",
    "\n",
    "    def calculate_membership(self, x):\n",
    "        if x <= self.start: \n",
    "            y = 0\n",
    "        if x > self.start and x <= self.top: \n",
    "            y = (x-self.start)/(self.top-self.start)\n",
    "        if x > self.top and x <= self.end:\n",
    "            y = (self.end - x)/(self.end - self.top)\n",
    "        if x > self.end:\n",
    "            y = 0\n",
    "        return y\n",
    "        \n",
    "class TrapezoidalMF:\n",
    "    \"\"\"Trapezoidal fuzzy logic membership function class.\"\"\"\n",
    "    def __init__(self, name, start, left_top, right_top, end):\n",
    "        self.name = name\n",
    "        self.start = start\n",
    "        self.left_top = left_top\n",
    "        self.right_top = right_top\n",
    "        self.end = end\n",
    "\n",
    "    def calculate_membership(self, x):\n",
    "        if x <= self.start: \n",
    "            y = 0\n",
    "        if x > self.start and x <= self.left_top: \n",
    "            y = (x - self.start)/(self.left_top - self.start)\n",
    "        if x > self.left_top and x <= self.right_top:\n",
    "            y = 1\n",
    "        if x > self.right_top and x <= self.end:\n",
    "            y = (self.end - x)/(self.end - self.right_top)\n",
    "        if x > self.end:\n",
    "            y = 0\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.99\n",
      "0.5\n",
      "1\n",
      "0.8500000000000001\n",
      "0.050000000000000044\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation by running the following statements\n",
    "# Enter your answers in the Google form to check them, round to two decimals\n",
    "\n",
    "triangular_mf = TriangularMF(\"medium\", 150, 250, 350)\n",
    "print(triangular_mf.calculate_membership(100))\n",
    "print(triangular_mf.calculate_membership(249))\n",
    "print(triangular_mf.calculate_membership(300))\n",
    "\n",
    "trapezoidal_mf = TrapezoidalMF(\"bad\", 0, 0, 2, 4)\n",
    "print(trapezoidal_mf.calculate_membership(1.2))\n",
    "print(trapezoidal_mf.calculate_membership(2.3))\n",
    "print(trapezoidal_mf.calculate_membership(3.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Inputs and output\n",
    "Theory\n",
    "\n",
    "The inputs and output of a FLS are represented through linguistic variables, which are variables whose values are words rather than numbers. A value of a linguistic variable is called a linguistic term.\n",
    "\n",
    "An example of a linguistic variable is 'income' (a variable we're using in the system we're programming), with the linguistic terms 'low', 'medium', 'high'.\n",
    "Practice\n",
    "\n",
    "Now we are going to define input and output variables, which are a collection of multiple membership functions.\n",
    "\n",
    "A variable's membership functions (self.mfs) should be a list of membership functions. Define the input variables income and quality and the output variable money with the name, range and membership functions represented in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    \"\"\"General class for variables in an FLS.\"\"\"\n",
    "    def __init__(self, name, range, mfs):\n",
    "        self.name = name\n",
    "        self.range = range\n",
    "        self.mfs = mfs\n",
    "\n",
    "    def calculate_memberships(self, x):\n",
    "        \"\"\"Test function to check whether\n",
    "        you put together the right mfs in your variables.\"\"\"\n",
    "        return {\n",
    "            mf.name : mf.calculate_membership(x)\n",
    "            for mf in self.mfs\n",
    "        }\n",
    "\n",
    "    def get_mf_by_name(self, name):\n",
    "        for mf in self.mfs:\n",
    "            if mf.name == name:\n",
    "                return mf\n",
    "\n",
    "class Input(Variable):\n",
    "    \"\"\"Class for input variables, inherits \n",
    "    variables and functions from superclass Variable.\"\"\"\n",
    "    def __init__(self, name, range, mfs):\n",
    "        super().__init__(name, range, mfs)\n",
    "        self.type = \"input\"\n",
    "\n",
    "class Output(Variable):\n",
    "    \"\"\"Class for output variables, inherits \n",
    "    variables and functions from superclass Variable.\"\"\"\n",
    "    def __init__(self, name, range, mfs):\n",
    "        super().__init__(name, range, mfs)\n",
    "        self.type = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input variable for your income\n",
    "# Your code here\n",
    "mfs_income = [TrapezoidalMF(\"low\", -100, 0, 200, 400), TriangularMF(\"medium\", 200, 500, 800), TrapezoidalMF(\"high\", 600, 800, 1000, 1200)]\n",
    "income = Input(\"income\", (0, 1000), mfs_income)\n",
    "\n",
    "# Input variable for the quality\n",
    "# Your code here\n",
    "mfs_quality = [TrapezoidalMF(\"bad\", -1, 0, 2, 4), TriangularMF(\"okay\", 2, 5, 8), TrapezoidalMF(\"amazing\", 6, 8, 10, 12)]\n",
    "quality = Input(\"quality\", (0, 10), mfs_quality)\n",
    "\n",
    "# Output variable for the amount of money\n",
    "# Your code here\n",
    "mfs_money = [TrapezoidalMF(\"low\", -100, 0, 100, 250), TriangularMF(\"medium\", 150, 250, 350), TrapezoidalMF(\"high\", 250, 400, 500, 600)]\n",
    "money = Output(\"money\", (0, 500), mfs_money)\n",
    "\n",
    "inputs = [income, quality]\n",
    "output = money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'low': 0, 'medium': 0.9633333333333334, 'high': 0}\n",
      "{'bad': 0, 'amazing': 0, 'okay': 0.6666666666666666}\n",
      "{'low': 0.18666666666666668, 'medium': 0.72, 'high': 0}\n",
      "income (0, 1000)\n",
      "inputs: income {'low': 0, 'medium': 0.9633333333333334, 'high': 0}\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation by running the following statements\n",
    "# Enter your answers in the Google form to check them, round to two decimals\n",
    "\n",
    "print(income.calculate_memberships(489))\n",
    "print(quality.calculate_memberships(6))\n",
    "print(output.calculate_memberships(222))\n",
    "\n",
    "print(income.name, income.range)\n",
    "print('inputs:', inputs[0].name, inputs[0].calculate_memberships(489))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Fuzzy Rules\n",
    "\n",
    "### Theory\n",
    "\n",
    "A fuzzy IF-THEN rule is composed of an antecedent and a consequent, like the implications you have seen with propositional and first order logic.\n",
    "- In the antecedent conditions for input variables are connected with an operator (AND, OR, NOT), e.g. \"IF x1 is mf1 AND x2 is mf3\", or \"IF x1 is mf1 OR x2 is mf2\".\n",
    "- The AND operator represents taking the intersection of fuzzy sets, which can be accomplished by choosing a T-Norm operation, such as minimum.\n",
    "- The OR operator represents taking the union of fuzzy sets, which can be accomplished by choosing a T-Conorm operation, such as maximum.\n",
    "- The NOT operator, the complement, is calculated by 1 minus a membership value. For example: NOT x1 is mf1, would be 1 - (membership of x1 to mf1).\n",
    "- By the use of the AND, NOT and OR we combine the different parts of the antecedent into a single number, which is the firing strength of the antecedent.\n",
    "- The consequent represents an action that we undertake if the rule fires.\n",
    "\n",
    "### Practice\n",
    "\n",
    "We are going to add some simple rules for our FLS: complete rules that do not have mixed operators. Here we represent a rule through 3 variables:\n",
    "- <b>Antecedent</b>, represented as a list of names of membership functions. The index of the name corresponds to the variable it belongs to, for example: [\"medium\", \"low\"], where \"medium\" belongs to the first variable in *inputs* and \"low\" corresponds to the second variable in *inputs*.\n",
    "- <b>Operator</b>: \"and\" or \"or\", let's choose \"and\".\n",
    "- <b>Consequent</b>: a string corresponding one of the membership functions of your output variable, for example \"high\".\n",
    "\n",
    "These three variables would then compose the rule \"IF income is medium AND quality is low THEN money is high.\"\n",
    "\n",
    "Complete the *calculate_firing_strength()*, that should function and check your answers by running the test statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Rule:\n",
    "    \"\"\"Fuzzy rule class, initialized with an antecedent (list of strings),\n",
    "    operator (string) and consequent (string).\"\"\"\n",
    "    def __init__(self, n, antecedent, operator, consequent):\n",
    "        self.number = n\n",
    "        self.antecedent = antecedent\n",
    "        self.operator = operator\n",
    "        self.consequent = consequent\n",
    "        self.firing_strength = 0\n",
    "\n",
    "    def calculate_firing_strength(self, datapoint, inputs):\n",
    "        # choosen min operator for T-norm\n",
    "        i = 0\n",
    "        self.firing_strength = 9999999999999999999\n",
    "        for input_ms in self.antecedent:\n",
    "            # print (i, input_ms, datapoint[i])\n",
    "            mslijst = inputs[i].calculate_memberships(datapoint[i])\n",
    "            msvalue = mslijst[input_ms]\n",
    "            self.firing_strength = min(self.firing_strength, msvalue)\n",
    "            # print (msvalue, self.firing_strength)\n",
    "            i += 1\n",
    "        # zou bovenstaand ook kunnen door calculate_memberships of vector van waarden te doen ???\n",
    "        return self.firing_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "1.0\n",
      "0\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation by checking the following statements\n",
    "# Enter your answers in the Google form to check them, round to two decimals\n",
    "\n",
    "rule1 = Rule(1, [\"low\", \"amazing\"], \"and\", \"low\")\n",
    "print(rule1.calculate_firing_strength([200, 6.5], inputs))\n",
    "print(rule1.calculate_firing_strength([0, 10], inputs))\n",
    "\n",
    "rule2 = Rule(2, [\"high\", \"bad\"], \"and\", \"high\")\n",
    "print(rule2.calculate_firing_strength([100, 8], inputs))\n",
    "print(rule2.calculate_firing_strength([700, 3], inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Fuzzy Rulebase\n",
    "\n",
    "\n",
    "### Theory\n",
    "\n",
    "A rulebase is simply a collection of all rules of the system!\n",
    "\n",
    "### Practice\n",
    "\n",
    "Our fuzzy rulebase is a collection of all rules. Create the following rules and initalize the fuzzy rulebase:\n",
    "- IF income is low AND quality is amazing THEN money is low\n",
    "- IF income is medium AND quality is amazing THEN money is low\n",
    "- IF income is high AND quality is amazing THEN money is low\n",
    "- IF income is low AND quality is okay THEN money is low\n",
    "- IF income is medium AND quality is okay THEN money is medium\n",
    "- IF income is high AND quality is okay THEN money is medium\n",
    "- IF income is low AND quality is bad THEN money is low\n",
    "- IF income is medium AND quality is bad THEN money is medium\n",
    "- IF income is high AND quality is bad THEN money is high\n",
    "\n",
    "Implement the *calculate_firing_strengths()* function that collects the highest firing strength found per membership function of the output variable in a dictionary or Counter object.\n",
    "For example, if the firing strengths for the rules listed above are 0, 0, 0, 0.5, 0.25, 0, 0, 0, 0 the result would look like this: *{\"low\":0.5, \"medium\":0.25, \"high\"0}*.\n",
    "\n",
    "Check the correctness of your function with the testing statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Rulebase:\n",
    "    \"\"\"The fuzzy rulebase collects all rules for the FLS, can\n",
    "    calculate the firing strengths of its rules.\"\"\"\n",
    "    def __init__(self, rules):\n",
    "        self.rules = rules\n",
    "\n",
    "    def calculate_firing_strengths(self, datapoint, inputs):\n",
    "        result = Counter()\n",
    "        for i, rule in enumerate(self.rules):\n",
    "            fs = rule.calculate_firing_strength(datapoint, inputs)\n",
    "            consequent = rule.consequent\n",
    "            if fs > result[consequent]:\n",
    "                result[consequent] = fs\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the rules listed in the question description\n",
    "# Your code here\n",
    "rule1 = Rule(1, [\"low\", \"amazing\"], \"and\", \"low\")\n",
    "rule2 = Rule(2, [\"medium\", \"amazing\"], \"and\", \"low\")\n",
    "rule3 = Rule(3, [\"high\", \"amazing\"], \"and\", \"low\")\n",
    "rule4 = Rule(4, [\"low\", \"okay\"], \"and\", \"low\")\n",
    "rule5 = Rule(5, [\"medium\", \"okay\"], \"and\", \"medium\")\n",
    "rule6 = Rule(6, [\"high\", \"okay\"], \"and\", \"medium\")\n",
    "rule7 = Rule(7, [\"low\", \"bad\"], \"and\", \"low\")\n",
    "rule8 = Rule(8, [\"medium\", \"bad\"], \"and\", \"medium\")\n",
    "rule9 = Rule(9, [\"high\", \"bad\"], \"and\", \"high\")\n",
    "\n",
    "# print('testfs: ', rule1.calculate_firing_strength([234, 7.5], inputs))\n",
    "\n",
    "rules = [rule1, rule2, rule3, rule4, rule5, rule6, rule7, rule8, rule9]\n",
    "\n",
    "rulebase = Rulebase(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'medium': 0.5})\n",
      "Counter({'low': 0.75, 'medium': 0.11333333333333333})\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation of calculate_firing_strengths()\n",
    "# Enter your answers in the Google form to check them, round to two decimals\n",
    "\n",
    "datapoint = [500, 3]\n",
    "print(rulebase.calculate_firing_strengths(datapoint, inputs))\n",
    "\n",
    "datapoint = [234, 7.5]\n",
    "print(rulebase.calculate_firing_strengths(datapoint, inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Inference (aggregation and defuzzification)\n",
    "\n",
    "### Theory\n",
    "\n",
    "In the Fuzzy Inference all parts of the fuzzy system come together: we are mapping an input to an output in the following way:\n",
    "1. Fuzzify the input.\n",
    "2. Calculate the firing strengths for the rules.\n",
    "3. Use the firing strength to determine the contribution of the consequent.\n",
    "4. Aggregate / collect all consequents.\n",
    "5. Defuzzify\n",
    "\n",
    "As already mentioned, there is Mamdani type inference and Takagi-Sugeno-Kang (TSK) type inference:\n",
    "- With Mamdani type inference we represent the consequents of fuzzy rules as fuzzy sets (using membership functions). We use a rule's firing strength to adapt the height of the membership function in the consequent, using the implication operator (minimum or product). The consequents are then aggregated into one area (taking the maximum of all consequents for the entire input range), on which we apply a defuzzification method, such as 'largest of max', 'smallest of max' or 'centroid'.\n",
    "- With TSK type inference we represent the consequents as a function of the input variables, or a constant. To combine the consequents into one output number we calculate a weighted average, where the weights are the rules' firing strengths.\n",
    "\n",
    "<img src=\"https://i.imgur.com/q5lzbsZ.png\"></img>\n",
    "<img src=\"https://i.imgur.com/Yl20dJL.png\"></img>\n",
    "\n",
    "In the following image multiple defuzzification methods are visualized:\n",
    "<img src=\"http://access.feld.cvut.cz/storage/201208252026_obr-15.png\"></img>\n",
    "\n",
    "### Practice\n",
    "\n",
    "We will finalize our system using Mamdani type inference by performing the following three steps:\n",
    "1. Gathering the largest firing strength per membership function of the output variable (implemented in your rulebase in Step 3)\n",
    "2. Discretizing the range of your output variable and applying the aggregation method (<b>max</b>): for every bin you find the maximum fuzzy membership value. Notice that the membership functions of the output variable are `cut off' according to the firing strengths, with the implication method (<b>min</b>).\n",
    "To accomplish this we perform two steps:\n",
    "    - First we find where the aggregated area starts and ends on the x-axis\n",
    "    - Second we discretize the area between start and end into 201 points (thus representing the area in 200 bins)\n",
    "3. Applying two defuzzification methods: implement smallest of max (<b>som</b>) and largest of max (<b>lom</b>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Reasoner:\n",
    "    def __init__(self, rulebase, inputs, output, n_points, defuzzification):\n",
    "        self.rulebase = rulebase\n",
    "        self.inputs = inputs\n",
    "        self.output = output\n",
    "        self.discretize = n_points\n",
    "        self.defuzzification = defuzzification\n",
    "\n",
    "    def inference(self, datapoint):\n",
    "        # 1. Calculate the highest firing strength found in the rules per \n",
    "        # membership function of the output variable\n",
    "        # looks like: {\"low\":0.5, \"medium\":0.25, \"high\":0}\n",
    "        firing_strengths = rulebase.calculate_firing_strengths(datapoint, inputs)\n",
    "\n",
    "        # 2. Aggragate and discretize\n",
    "        # looks like: [(0.0, 1), (1.2437810945273631, 1), (2.4875621890547261, 1), (3.7313432835820892, 1), ...]\n",
    "        input_value_pairs = self.aggregate(firing_strengths)\n",
    "\n",
    "        # 3. Defuzzify\n",
    "        # looks like a scalar\n",
    "        crisp_output = self.defuzzify(input_value_pairs)\n",
    "        return crisp_output\n",
    "\n",
    "    def aggregate(self, firing_strengths):  \n",
    "        # First find where the aggrageted area starts and ends\n",
    "        # Your code here\n",
    "        agg_start = self.output.range[0]\n",
    "        agg_end = self.output.range[1]\n",
    "        \n",
    "        # Second discretize this area and aggragate\n",
    "        aantal = self.discretize\n",
    "        breedte = (agg_end - agg_start)/(aantal-1)\n",
    "        # print(aantal, 'breedte: ', breedte)\n",
    "        input_value_pairs = []\n",
    "        for n in range(aantal):\n",
    "            x = agg_start + n * breedte\n",
    "            mslijst = self.output.calculate_memberships(x)\n",
    "            # print('x:', x), print('mslijst: ', mslijst)\n",
    "            # print('fs: ', firing_strengths)\n",
    "            value = 0\n",
    "            for ms in mslijst: \n",
    "                ms_min = min(mslijst[ms], firing_strengths[ms])\n",
    "                value = max(ms_min, value)\n",
    "                # print(ms_min, value)\n",
    "            # print(value)\n",
    "            input_value_pairs.append((x, value))\n",
    "        return input_value_pairs\n",
    "\n",
    "    def defuzzify(self, input_value_pairs):\n",
    "        maxms = 0\n",
    "        crisp_value = 9999\n",
    "        if self.defuzzification ==\"som\":    \n",
    "            for value_pair in input_value_pairs:\n",
    "                if value_pair[1]>maxms:\n",
    "                    maxms = value_pair[1]\n",
    "                    crisp_value = value_pair[0]\n",
    "        elif self.defuzzification == \"lom\":\n",
    "            for value_pair in input_value_pairs:\n",
    "                if value_pair[1]>=maxms:\n",
    "                    maxms = value_pair[1]\n",
    "                    crisp_value = value_pair[0]\n",
    "        # crisp_value = 9999 is eigenlijk foutsituatie\n",
    "        return crisp_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "265\n",
      "200\n",
      "100\n",
      "235\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation of the fuzzy inference\n",
    "# Enter your answers in the Google form to check them, round to two decimals\n",
    "\n",
    "thinker = Reasoner(rulebase, inputs, output, 201, \"som\")\n",
    "datapoint = [100, 1]\n",
    "# firing_strengths = rulebase.calculate_firing_strengths(datapoint, inputs)\n",
    "# print(\"fs(100,1):\", firing_strengths)\n",
    "# print(thinker.aggregate(firing_strengths))\n",
    "print(round(thinker.inference(datapoint)))\n",
    "\n",
    "thinker = Reasoner(rulebase, inputs, output, 101, \"lom\")\n",
    "datapoint = [550, 4.5]\n",
    "# firing_strengths = rulebase.calculate_firing_strengths(datapoint, inputs)\n",
    "# print(\"fs(550,4.5):\", firing_strengths)\n",
    "print(round(thinker.inference(datapoint)))\n",
    "\n",
    "thinker = Reasoner(rulebase, inputs, output, 201, \"som\")\n",
    "datapoint = [900, 6.5]\n",
    "# firing_strengths = rulebase.calculate_firing_strengths(datapoint, inputs)\n",
    "# print(\"fs(900,6.5):\", firing_strengths)\n",
    "print(round(thinker.inference(datapoint)))\n",
    "\n",
    "thinker = Reasoner(rulebase, inputs, output, 201, \"lom\")\n",
    "datapoint = [100, 1]\n",
    "print(round(thinker.inference(datapoint)))\n",
    "\n",
    "thinker = Reasoner(rulebase, inputs, output, 101, \"som\")\n",
    "datapoint = [550, 4.5]\n",
    "print(round(thinker.inference(datapoint)))\n",
    "\n",
    "thinker = Reasoner(rulebase, inputs, output, 201, \"lom\")\n",
    "datapoint = [900, 6.5]\n",
    "print(round(thinker.inference(datapoint)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
